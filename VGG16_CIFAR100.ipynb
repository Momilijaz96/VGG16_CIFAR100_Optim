{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16-CIFAR100.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7JU1Mfvde2AG",
        "2g65SO2tfYES",
        "TS40XVWZqUNh"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnsyueTmRuFr"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpLwZxqnkIvs"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JU1Mfvde2AG"
      },
      "source": [
        "# Import CIFAR-100 and Resize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b0GiF4QUIqL"
      },
      "source": [
        "resize = transforms.Compose([transforms.Resize(64), transforms.ToTensor()])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9nbu4BoSSj_",
        "outputId": "efd7ff3d-ebd0-45f9-ed59-3fd9da9ae11a"
      },
      "source": [
        "train_set = datasets.CIFAR100(root=\"data\", train=True, download=True, transform=resize)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrYMgq0mSXIP",
        "outputId": "9c87d888-37e0-4131-872e-d40839f3264d"
      },
      "source": [
        "test_set = datasets.CIFAR100(root=\"data\", train=False, download=True, transform=resize)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7ixv8dFWPRE",
        "outputId": "87b5b99f-dbf4-405e-aaa6-fe351dcecf9f"
      },
      "source": [
        "train_set[0][0].shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BalGnR67WQrB",
        "outputId": "278891f3-39ad-4d84-e954-9388726de393"
      },
      "source": [
        "test_set[0][0].shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g65SO2tfYES"
      },
      "source": [
        "# VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR51S8hEfaMH"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "model = models.vgg16(pretrained=True) #130million+ parameters\n",
        "\n",
        "\n",
        "#Freeze all model parameters\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "#Add on classifier\n",
        "n_classes=100\n",
        "n_inputs=4096\n",
        "model.classifier[6] = nn.Sequential(\n",
        "                      nn.Linear(n_inputs, n_classes))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdBM_c17kXNx"
      },
      "source": [
        "model=model.to(device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3qbdXxjkbOm",
        "outputId": "d386a9cb-0653-46b9-b040-25214dd7fb1d"
      },
      "source": [
        "device"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlCn31Vefi1e",
        "outputId": "554e7aaf-0893-4ce4-ab25-6b5e413ab9b7"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Sequential(\n",
            "      (0): Linear(in_features=4096, out_features=100, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqx8S8jIe_pM"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OXROzc3aNSd"
      },
      "source": [
        "train_dataloader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_set, batch_size=64, shuffle=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hcI-3AtgFHu"
      },
      "source": [
        "criterion=torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCp8TFGSfzYx",
        "outputId": "1353d3e2-7ee1-4fc2-c1e2-7ded09388cad"
      },
      "source": [
        "n_epochs = 50\n",
        "train_loss = []\n",
        "for epoch in range(n_epochs):\n",
        "  for data, targets in train_dataloader:\n",
        "    data=data.to(device)\n",
        "    targets=targets.to(device)\n",
        "    # Generate predictions\n",
        "    out = model(data)\n",
        "    # Calculate loss\n",
        "    loss = criterion(out, targets)\n",
        "    train_loss.append(loss)\n",
        "    #Reset the gradients\n",
        "    optimizer.zero_grad()\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    # Update model parameters\n",
        "    optimizer.step()\n",
        "\n",
        "  #Evaluation\n",
        "  model.eval()\n",
        "\n",
        "  #Train Evaluation\n",
        "  train_acc = 0\n",
        "  train_acc_l = []\n",
        "  for data, targets in train_dataloader:\n",
        "    data = data.to(device)\n",
        "    targets = targets.to(device)\n",
        "    ps = model(data)\n",
        "    #Get index of class label\n",
        "    _,preds = torch.max(ps,1)\n",
        "    #Get accuracy\n",
        "    train_acc += torch.sum(preds == targets)\n",
        "  train_acc_l.append(train_acc/500)\n",
        "\n",
        "  #Test Evaluation\n",
        "  test_acc = 0\n",
        "  test_acc_l = []\n",
        "  for data, targets in test_dataloader:\n",
        "    data = data.to(device)\n",
        "    targets = targets.to(device)\n",
        "    ps = model(data)\n",
        "    #Get index of class label\n",
        "    _,preds = torch.max(ps,1)\n",
        "    #Get accuracy\n",
        "    test_acc += torch.sum(preds == targets)\n",
        "  test_acc_l.append(test_acc/500)\n",
        "\n",
        "  print(f'Epoch: {epoch+1}\\t Loss: {loss:.4f}\\t Train_Acc: {train_acc/500:.4f}\\t Val_Acc: {test_acc/100:.4f}')\n",
        "\n",
        "  model.train()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\t Loss: 2.1265\t Train_Acc: 42.3720\t Val_Acc: 36.0700\n",
            "Epoch: 2\t Loss: 2.9099\t Train_Acc: 46.9540\t Val_Acc: 37.5300\n",
            "Epoch: 3\t Loss: 2.8372\t Train_Acc: 50.4140\t Val_Acc: 38.5500\n",
            "Epoch: 4\t Loss: 3.7438\t Train_Acc: 51.1960\t Val_Acc: 37.7500\n",
            "Epoch: 5\t Loss: 3.1873\t Train_Acc: 52.8200\t Val_Acc: 37.9700\n",
            "Epoch: 6\t Loss: 3.9083\t Train_Acc: 54.2900\t Val_Acc: 38.6300\n",
            "Epoch: 7\t Loss: 2.4070\t Train_Acc: 54.2340\t Val_Acc: 38.1100\n",
            "Epoch: 8\t Loss: 2.3899\t Train_Acc: 56.5140\t Val_Acc: 39.2900\n",
            "Epoch: 9\t Loss: 2.9042\t Train_Acc: 56.7400\t Val_Acc: 39.4000\n",
            "Epoch: 10\t Loss: 1.7386\t Train_Acc: 57.1180\t Val_Acc: 38.8800\n",
            "Epoch: 11\t Loss: 3.6280\t Train_Acc: 57.0000\t Val_Acc: 39.3000\n",
            "Epoch: 12\t Loss: 2.3169\t Train_Acc: 57.6960\t Val_Acc: 39.2300\n",
            "Epoch: 13\t Loss: 3.2330\t Train_Acc: 58.8460\t Val_Acc: 39.3300\n",
            "Epoch: 14\t Loss: 2.7955\t Train_Acc: 58.5120\t Val_Acc: 39.3600\n",
            "Epoch: 15\t Loss: 3.5749\t Train_Acc: 58.7320\t Val_Acc: 39.1100\n",
            "Epoch: 16\t Loss: 2.8415\t Train_Acc: 58.8320\t Val_Acc: 39.1800\n",
            "Epoch: 17\t Loss: 2.3438\t Train_Acc: 60.1360\t Val_Acc: 39.2600\n",
            "Epoch: 18\t Loss: 2.2354\t Train_Acc: 59.1920\t Val_Acc: 39.1300\n",
            "Epoch: 19\t Loss: 1.8867\t Train_Acc: 60.2540\t Val_Acc: 39.6800\n",
            "Epoch: 20\t Loss: 3.1369\t Train_Acc: 60.5220\t Val_Acc: 39.7200\n",
            "Epoch: 21\t Loss: 3.4871\t Train_Acc: 59.8700\t Val_Acc: 39.8600\n",
            "Epoch: 22\t Loss: 2.7304\t Train_Acc: 60.2980\t Val_Acc: 39.7400\n",
            "Epoch: 23\t Loss: 2.4354\t Train_Acc: 60.1840\t Val_Acc: 40.0500\n",
            "Epoch: 24\t Loss: 2.3628\t Train_Acc: 60.9000\t Val_Acc: 39.6400\n",
            "Epoch: 25\t Loss: 2.2440\t Train_Acc: 60.9040\t Val_Acc: 39.3900\n",
            "Epoch: 26\t Loss: 2.0196\t Train_Acc: 61.0140\t Val_Acc: 39.6900\n",
            "Epoch: 27\t Loss: 2.8009\t Train_Acc: 61.3880\t Val_Acc: 39.8800\n",
            "Epoch: 28\t Loss: 3.2956\t Train_Acc: 62.2320\t Val_Acc: 39.8100\n",
            "Epoch: 29\t Loss: 2.4462\t Train_Acc: 61.6320\t Val_Acc: 39.6100\n",
            "Epoch: 30\t Loss: 2.5105\t Train_Acc: 62.0460\t Val_Acc: 40.0200\n",
            "Epoch: 31\t Loss: 1.9390\t Train_Acc: 62.0520\t Val_Acc: 39.8500\n",
            "Epoch: 32\t Loss: 3.8816\t Train_Acc: 61.9680\t Val_Acc: 40.0700\n",
            "Epoch: 33\t Loss: 4.2403\t Train_Acc: 62.2060\t Val_Acc: 40.0200\n",
            "Epoch: 34\t Loss: 2.1341\t Train_Acc: 61.6300\t Val_Acc: 39.9900\n",
            "Epoch: 35\t Loss: 3.0160\t Train_Acc: 62.2800\t Val_Acc: 39.7400\n",
            "Epoch: 36\t Loss: 3.0613\t Train_Acc: 62.6420\t Val_Acc: 39.4500\n",
            "Epoch: 37\t Loss: 1.6480\t Train_Acc: 62.5640\t Val_Acc: 39.6500\n",
            "Epoch: 38\t Loss: 2.8018\t Train_Acc: 62.3360\t Val_Acc: 39.4200\n",
            "Epoch: 39\t Loss: 4.0756\t Train_Acc: 62.4120\t Val_Acc: 39.8700\n",
            "Epoch: 40\t Loss: 2.3216\t Train_Acc: 62.5140\t Val_Acc: 39.7500\n",
            "Epoch: 41\t Loss: 2.5550\t Train_Acc: 62.5060\t Val_Acc: 39.6900\n",
            "Epoch: 42\t Loss: 2.7238\t Train_Acc: 62.1460\t Val_Acc: 39.5200\n",
            "Epoch: 43\t Loss: 2.8166\t Train_Acc: 62.2280\t Val_Acc: 39.8900\n",
            "Epoch: 44\t Loss: 1.9992\t Train_Acc: 62.8520\t Val_Acc: 39.7400\n",
            "Epoch: 45\t Loss: 2.6877\t Train_Acc: 62.2380\t Val_Acc: 39.9100\n",
            "Epoch: 46\t Loss: 2.5986\t Train_Acc: 61.4820\t Val_Acc: 39.2800\n",
            "Epoch: 47\t Loss: 2.8859\t Train_Acc: 62.7960\t Val_Acc: 39.2400\n",
            "Epoch: 48\t Loss: 2.3979\t Train_Acc: 62.3040\t Val_Acc: 39.1600\n",
            "Epoch: 49\t Loss: 2.6117\t Train_Acc: 62.9520\t Val_Acc: 39.4400\n",
            "Epoch: 50\t Loss: 3.5934\t Train_Acc: 62.8360\t Val_Acc: 40.2900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS40XVWZqUNh"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1YUq1sBhxH_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1503639a-cc52-4e26-f9e4-9453aef77c87"
      },
      "source": [
        "'''\n",
        "model.eval()\n",
        "test_acc=0\n",
        "for data, targets in test_dataloader:\n",
        "  data=data.to(device)\n",
        "  targets=targets.to(device)\n",
        "  log_ps = model(data)\n",
        "  # Convert to probabilities\n",
        "  ps = torch.exp(log_ps)\n",
        "  #Get index of class label\n",
        "  _,preds=torch.max(ps,1)\n",
        "  #Get accuracy\n",
        "  test_acc += torch.sum(preds == targets)\n",
        "\n",
        "test_acc/len(test_set)\n",
        "'''"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nmodel.eval()\\ntest_acc=0\\nfor data, targets in test_dataloader:\\n  data=data.to(device)\\n  targets=targets.to(device)\\n  log_ps = model(data)\\n  # Convert to probabilities\\n  ps = torch.exp(log_ps)\\n  #Get index of class label\\n  _,preds=torch.max(ps,1)\\n  #Get accuracy\\n  test_acc += torch.sum(preds == targets)\\n\\ntest_acc/len(test_set)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}